---
layout: post
title:  "You Only Look Once "
summary: "Yolov1 Thesis"
author: cupark
date: '2022-12-18 20:00:23 +0530'
category: 1-Stage
thumbnail: /assets/img/posts/yolov1/thumb_yolo.PNG
keywords: best jekyll themes
permalink: 
usemathjax: true
---

### 무슨일이야

### ========================================================================
###  1.	Object Detection – Regression Problem 관점으로 1Stage 해결
###  2.	논리적 구조 
###    1)	Input Image를 Grid 분할한다.
###    2)	Feature Map을 통하여 Prediction Tensor를 생성한다. 
###    3)	Prediction Tensor를 통하여 3가지 정보를 추출한다.
###      (1)	Bounding Box 정보: 각 Bounding Box는 Confidence-Score를 갖는다.
###      (2)	Confidence-Score 정보: x, y, w, h, Pc (w, h 는 전체 이미지의 W, H를 나누어 사용)
###      (3)	Conditional Class Probability 정보: Pr(Object) * IOU를 통하여 0, 1을 반환한다. 
###          A.	IOU: Conv를 진행한 뒤 결과로 반환된 Prediction Box(Bounding Box)가 Ground Truth Box와 얼마나 중첩되어 있는가를 비교한다. 
###          B.	NMS(Non Maximum Suppresion):GTB와 가장 IOU가 높은 하나의 Prediction Box를 Loss Function에 사용한다. 
###             선정된 Box를 1로 선정되지 않은 박스는 0을 사용하여 Loss Function에서 제외한다. 
###    4)	각 Grid cell은 다중의 Conditional Class Probability를 갖는다. (Pr(Class i | Object)
###    5)	사전에 정의된 S (Grid 개수), B (Bounding Box 개수), C (Classification 개수)에 따른 1차원 Output Tensor가 생성된다. 
###    6)	Output Tensor를 통하여 Object Detection을 수행한다.
### ========================================================================

###  1. 객체 탐지에 있어서 중요도는 객체 분류에서 탐지의 성능으로 바뀌었다.
###     객체 탐지의 성능을 올리기 위하여 객체 탐지를 공간적으로 분리된 Bounding Box나 관련 클래스의 확률에 대한 회귀 문제로 프레임화하였다.
###     하나의 신경망은 전체 이미지로부터 Bounding Box와 클래스 확률에 대하여 바로 한번에 평가하여 예측한다. 
###     전체 탐지 파이프라인이 하나의 신경망으로 되어있기 때문에 처음부터 끝까지 최적화를 직접적으로 할 수 있다.
 
###  2. 이전의 Object Detection의 동작 방식 
###     1) Single Window나 Regional Proposal Method(물체가 있을것으로 예상되는 후보 Object위치를 제시하는 메소드)등을 통하여 바운딩 박스를 잡은 후 
###        바운딩 박스에 대하여 분류를 수행했다.
###     2) 1)의 방식을 이용하기 때문에 (1) 바운딩 박스 처리 Stage, (2) 바운딩 처리된 박스에 대한 분류 작업 Stage로 2개의 Detection Stage를 사용한다.
 
###  3. 이전의 Object Detection과 Yolo의 차이 
###     1) 기존 Detection에 2Stage 방식을 1Stage안에 처리한다. 
###       (1) Bounding Box와 Classification을 하나의 Convolution Layer에서 처리하는 통합인식(Unified Detection)을 한다.
###     2) 학습 파이프라인이 기존의 Detection 모델에 비하여 간단한 구조를 갖기 때문에 학습과 예측에 속도가 빠르다.
###     3) 1 Stage Detector 동작 방식 
###        - 이미지 -> Convolution Layer -> Fully Connected Layer -> Reshape -> Output Tensor -> For each grid cell
###     4) 2 Stage Detector 동작 방식
###        - 이미지 -> Regional Proposal -> Classification : Object Yes or No, Box Regression -> Proposed Regions
###        - 이미지 -> Classification -> Feature Map    
###        - Proposed Regions + Feature Map -> Fully Connected Layer -> For each proposed region
       
###  4. Main Contribution
###     1) Object Detection을 Regression problem으로 관점을 전환함   
###     2) Unified Architecture 
###        - 하나의 신경망으로 Classification과 Localization을 예측 
###     3) DPM, RCNN 모델보다 속도를 개선
###     4) 여러 도메인에서 Object Detection이 가능
 
###  5. Yolov1 Workflow (S(Size) =4, B(Bounding Box) =2, C(Classification) = 20)
###     1) Input Image(Original Information)을 S x S의 사이즈로 그리드 분할을 진행한다.
###     2) Input Image의 Feature Map을 통하여 Prediction Tensor를 생성한다. 
###        Prediction Tensor : (1) Bounding Box Information each Grid cell 
###                            (2) Confidence-Score each Grid cell
###                            (3) Conditional Class Probability each Grid cell
###     3) 생성된 Prediction Tensor를 통하여 Bounding Box를 조정 및 분류한다.
    
###     4-1) 각각의 Grid cell은 N개의 Bounding Box와 각 Bounding Box에 대한 Confidence-Score를 갖는다. (병렬적으로 진행)
###        ** Bounding Box #1 = x1, y1, w1, h1, Pc1(Confidence-Score)를 갖는다.
###           ** 위에서 사용되는 w1, h1의 값은 Bounding Box의 w값에 전체 이미지 w를 나누어 Normailize하여 사용한다. (h도 마찬가지)
###        ** Bounding Box #2 = x2, y2, w2, h2, Pc2(Confidence-Score)를 갖는다.          
###        ** Confidence-Score = Pr(Object)*IOU, Pr(Object)는 물체가 Bounding Box내에 있으면 1, 없으면 0을 갖는다.
       
###     4-2) 각각의 Grid cell은 M개의 Conditional Class Probability를 갖는다. (병렬적으로 진행)
###        ** Pr ( Class i | Object ) : 물체가 Bounding Box 내에 있을때, Grid cell에 있는 Object가 i번째 class에 속할 확률 
###           ex) c1 : 고양이, c2 : 강아지, c3 : 코끼리, c4 : 말, .... , c20 : 호랑이
###               c1 = 0.9, c2 = 0.1, c3 = 0.08, c4 = 0.02, .... , c20 = 0.3
    
    
###     5) 1) ~ 5)의 결과의 Output Tensor는 각각의 Bounding Box는 (x,y)좌표, w, h, confidence를 갖는다. 
###        ** x1, y1, w1, h1, Pc1, x2, y2, w2, h2, Pc2, c1, c2, c3, .. , c20
###           ------------BB#1(5)  ------------BB#2(5)  --------------Pr(20)  = 30개
          
###        ** Grid Size가 4였으므로, 4 x 4 x 30의 Output Tensor가 만들어진다.   
          
###        **x,y는 Bounding Box의 중심점을 의한다. 해당 x, y의 위치가 Grid cell에서 x가 가장왼쪽, y가 중심에 있다면 x = 0, y = 0.5를 갖는다.
###     6) 탐지된 객체에 대한 Bounding Box와 Confidence-Score, Conditional Class Probability를 통하여 Object Detection을 수행한다.
   
###  6. GoogLeNet Model Network Design 
###     1) 24 Convolution Layer + 2 Fully Connected Layer 
###        - Pretrained = 20 Convolution Layer                            : 1,000 Class ImageNet (224 x 224)
###        - Fine-Tuned =  4 Convolution Layer + 2 Fully Connected Layer  : PASCAL VOC (448 x 448)
###        - Reduction Layer = 1 x 1 Reduction Layer로 연산량 감소 ( 1 x 1 Conv, filter의 개수를 Input dim보다 작게 함)
###          Conv Layer 중첩에 따른 연산량 증가를 막기위한 Reduction Layer를 사용.
  
###  7. Training Stage
###     1) 특정 Object에 Responsible한 cell i는 GT(Ground Truth) Box의 중심이 위치하는 cell로 할당 
###        - ex) GT Box가 cell 4, 5, 6, 7에 거쳐져 있을때 그 중심이 Grid Cell 6에 있다면 Responsible한 cell을 6번째 cell로 할당한다. 
###     2) 6.에 Inference 단계에서는 Bounding Box를 여러개 예측하는것으로 나타났지만, 학습할때는 Bounding Box 1개를 선택하여 사용한다. 
###        1개의 Bounding Box를 선정하는 기준은 IOU이다. 학습단계에서 GTB와 IOU가 가장 높은 Prediction Box 1개를 활용하여 학습을 진행한다. 
###       - IOU : Conv Layer를 통해 생성된 Prediction Box 중에서 GTB와 겹치는 부분 정도를 의미한다. 
###       - 결과로 GTB와의 IOU가 가장 높은 1개의 Box만을 사용하여 학습한다. 
###       - 선정된 1개의 Box를 Loss Function에 어떻게 반영할 것인가. 
###         사용되는 Box의 IOU 스칼라 값을 1로 선언하면 사용하고, 0으로 하면 사용하지 않아 Loss값이 전파되지 않는다. 
###     3) MSE : (TrainingStageMSE파일)
###         (1) 모든 Grid cell에서 예측한 N개의 Bounding Box의 좌표와 Ground Truth Box의 좌표 
###         (2) 모든 Grid cell에서 예측한 M개의 Pr(Class i | Object)과 Ground Truth 값
###         (3) 모든 Grid cell의 Pr(Object) * IOU 예측값과 Ground Truth Box의 값
###         (4) (1) + (2) + (3) => Grid cell에 Object가 존재하는 경우의 오차와 Predictor Box로 선정된 경우의 오차만을 학습한다. 
        
###  8. Inference Stage
###     1) Input Image -> Conv Layers -> Output Tensor -> Class-specific Confidence Score
###     2) S(Size) =4, B(Bounding Box) =2, C(Classification) = 20, pc = Confidence Score
###        Output Tensor(4 x 4 x 30) = x1, y2, w1, h1, pc1, x2, y2, w2, h2, pc2, c1, c2, c3, ... , c20 (30개)
###        => Class-Specific Confidence Score =  pc(Confidence Score) x Class Probability (c1, c2, c3, ... , c20)
###        (1) BBox#1 Output Tensor = x1, y2, w1, h1, pc1, c1, c2, c3, ... , c20
###        (2) BBox#2 Output Tensor = x2, y2, w2, h2, pc2, c1, c2, c3, ... , c20 
###        .
###        .
###        .
###        (3) BBox#1's Class-Specific Confidence Score = x1, y1, w1, h1, pc1 x (c1, c2, c3, ... , c20)
###        (4) BBox#2's Class-Specific Confidence Score = x2, y2, w2, h2, pc2 x (c1, c2, c3, ... , c20)
###        (5) BBox#32's Class-Specific Confidence Score = x32, y32, w32, h32, pc32 x (c1, c2, c3, ... , c20)
       
###        - 4 x 4 Grid cell, Bounding Box = 2 -> 4 x 4 x 2 = 32개의 Bounding Box가 생성 
###          : 1개의 Object에 대한 Bounding Box가 32개인데 Grid cell이 더 나누어지거나 cell에 할당된 Bounding Box가 많아지면 
###            많은 Bounding Box가 처리되어야 한다. 이부분을 해결하기 위한 알고리즘으로 NMS를 사용한다. 
           
###        (6) NMS(Non Maximum Suppresion) : 하나의 객체에 대해 많은 Bounding Box 중 가장 신뢰도가 높은 하나의 Bounding Box만 남기는 
###            Post-precessing이다. 단, Bbox#1 내부 c1, c2, c3 끼리의 비교가 아닌 Bbox#1의 c1, Bbox#2의 c1, ... , Bbox#32의 c1인 Class 단위로
###            NMS를 진행해야한다. 
###            - B : 생성된 Bounding Box의 총 집합 
###            - S : B의 Class-Specific Confidence Score
###            - N : overlap 임계치 
###            - D : 최종 선택될 B를 담을 리스트 
           - psuedo code 
              for i in range(len(class)):
                 if bbox['pc'] < 0:
                    bbox_list.remove(bbox)
              while (not processed bbox exists):
                 selected_bbox = bbox with the hightest pc
                 bbox_list.remove(other boxes which has high IOU with selected_bbox)
                 
###  9. 한계점
###     1) 작은 물에체 대해서 탐지 성능이 낮아진다.
###        - Object가 작아지는 경우 IOU의 값의 차이도 줄어들어 근소한 차이로 Predictor가 결정되기 때문이다.
       
###     2) Object의 비율이 달라지면 Detection의 성능이 낮아진다. 
###        - 대부분의 Detection 모델의 공통적인 한계점이다.
